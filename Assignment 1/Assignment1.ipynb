{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import Imputer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 13)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Amazon.csv')\n",
    "data = data[0:1000]\n",
    "data.shape\n",
    "# data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define y\n",
    "y = data.iloc[:, 12].values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bag of words on text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count = CountVectorizer()\n",
    "\n",
    "type(data.Text)\n",
    "textArray = data.Text.as_matrix()\n",
    "type(textArray)\n",
    "features = count.fit_transform(textArray)\n",
    "XText = features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "#bag of words on summary\n",
    "# creating newSummary with \"no summary given\" where summary does not exist.\n",
    "# data['SummaryFill'] = np.where(pd.isnull(data['Summary']) == True, 'no summary given', data['Summary'])\n",
    "data['Summary'].fillna('null', inplace=True)\n",
    "print(type(data.Summary))\n",
    "summaryArray = data.Summary.as_matrix()\n",
    "type(summaryArray)\n",
    "features = count.fit_transform(summaryArray)\n",
    "XSummary = features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# features from Amazon.csv to add to feature set\n",
    "data['reviewLen'] = data['Text'].str.len()\n",
    "data['summaryLen'] = data['Summary'].str.len()\n",
    "data['usernameWords'] = data ['ProfileName'].str.split().str.len()\n",
    "\n",
    "XScore = data.iloc[:, 7].values.reshape(data.shape[0], 1)\n",
    "XreviewLen = data.iloc[:, 13].values.reshape(data.shape[0], 1)\n",
    "XsummaryLen = data.iloc[:, 14].values.reshape(data.shape[0], 1)\n",
    "XusernameWords =data.iloc[:, 15].values.reshape(data.shape[0], 1)\n",
    "\n",
    "Xtoadd = np.concatenate((XText,XSummary,XScore,XreviewLen,XsummaryLen,XusernameWords), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vectorize Bag of Words from Summary text; as sparse matrix\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "hv = HashingVectorizer(n_features=2 ** 17, non_negative=True)\n",
    "XhashText = hv.transform(data.Text)\n",
    "XhashSummary = hv.transform(data.Summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fix missing values in summary\n",
    "# data[\"Summary\"].fillna(data[\"Summary\"].mean(), inplace=True)\n",
    "# data[\"Summary\"].fillna('pad')\n",
    "# data[\"Summary\"].fillna('pad')\n",
    "# data.Summary.fillna(0)\n",
    "# data['newSummary'] = np.where(pd.isnull(data['Summary']) == True, 'no summary given', data['Summary'])\n",
    "# Y = hv.transform(data.Summary)\n",
    "\n",
    "# imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "# imp.fit(hv.transform(data.Summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert to CSR\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "XtoaddSparse = csr_matrix(Xtoadd)\n",
    "Xfinal = hstack([Xtoadd, XtoaddSparse])\n",
    "X = csr_matrix(Xfinal)\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "X = imp.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 16288)\n",
      "(700,)\n",
      "(300, 16288)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# report on training and test sets\n",
    "def print_results():\n",
    "    print('Error rate on training set: ')\n",
    "    print((y_train != y_pred).sum() / X_train.shape[0])\n",
    "    print('Accuracy rate on training set: ')\n",
    "    print(1 - (y_train != y_pred).sum() / X_train.shape[0])\n",
    "    print('True positive rate on training tet:')\n",
    "    print(((y_train==True) & (y_pred==True)).sum() / y_train.sum())\n",
    "    print('**************')\n",
    "    print('Error rate on test set: ')\n",
    "    print((y_test != y_pred_test).sum() / X_test.shape[0])\n",
    "    print('Accuracy rate on test set: ')\n",
    "    print(1 - (y_test != y_pred_test).sum() / X_test.shape[0])\n",
    "    print('True positive rate on test set')\n",
    "    print(((y_test==True) & (y_pred_test==True)).sum() / y_test.sum())\n",
    "    print('True negative rate on test set')\n",
    "    print(((y_test==False) & (y_pred_test==False)).sum() / (y_test.shape[0] - y_test.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(C=1.0, random_state=0)\n",
    "y_pred = lr.fit(X_train, y_train).predict(X_train)\n",
    "y_pred_test = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate on training set: \n",
      "0.0\n",
      "Accuracy rate on training set: \n",
      "1.0\n",
      "True positive rate on training tet:\n",
      "1.0\n",
      "**************\n",
      "Error rate on test set: \n",
      "0.0533333333333\n",
      "Accuracy rate on test set: \n",
      "0.946666666667\n",
      "True positive rate on test set\n",
      "0.0769230769231\n",
      "True negative rate on test set\n",
      "0.98606271777\n"
     ]
    }
   ],
   "source": [
    "print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate on training set: \n",
      "0.0\n",
      "Accuracy rate on training set: \n",
      "1.0\n",
      "True positive rate on training tet:\n",
      "1.0\n",
      "**************\n",
      "Error rate on test set: \n",
      "0.09\n",
      "Accuracy rate on test set: \n",
      "0.91\n",
      "True positive rate on test set\n",
      "0.0\n",
      "True negative rate on test set\n",
      "0.951219512195\n"
     ]
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate on training set: \n",
      "0.0\n",
      "Accuracy rate on training set: \n",
      "1.0\n",
      "True positive rate on training tet:\n",
      "1.0\n",
      "**************\n",
      "Error rate on test set: \n",
      "0.0566666666667\n",
      "Accuracy rate on test set: \n",
      "0.943333333333\n",
      "True positive rate on test set\n",
      "0.0769230769231\n",
      "True negative rate on test set\n",
      "0.982578397213\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='linear', C=1.0, random_state=0)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_train)\n",
    "y_pred_test = svm.predict(X_test)\n",
    "print_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
